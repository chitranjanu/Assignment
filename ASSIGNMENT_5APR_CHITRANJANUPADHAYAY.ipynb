{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c47cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer1.\n",
    "\n",
    "# Answer1.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import the dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(dataset.head())\n",
    "\n",
    "# Get descriptive statistics of the variables\n",
    "print(dataset.describe())\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = dataset.corr()\n",
    "\n",
    "# Create a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Plot histograms of the variables\n",
    "dataset.hist(figsize=(10, 8))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Create pairplots of the variables\n",
    "sns.pairplot(dataset, hue='Outcome')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a9da9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer2.\n",
    "\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Import the dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Handling missing values\n",
    "dataset = dataset.dropna()  # Remove rows with missing values\n",
    "# Alternatively, you can impute missing values\n",
    "# dataset = dataset.fillna(dataset.mean())  # Replace with mean\n",
    "\n",
    "# Handling outliers using z-scores\n",
    "z_scores = zscore(dataset[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']])\n",
    "dataset = dataset[(z_scores < 3).all(axis=1)]  # Remove rows with z-scores above 3\n",
    "\n",
    "# Handling categorical variables (if any)\n",
    "# dataset = pd.get_dummies(dataset, columns=['CategoricalVariable'])  # Convert categorical variables to dummy variables\n",
    "\n",
    "# Confirm the changes\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caee0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer3.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import the dataset\n",
    "dataset = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Preprocess the dataset (clean missing values, remove outliers, etc.)\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = dataset.drop('Outcome', axis=1)\n",
    "y = dataset['Outcome']\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random_seed = 42\n",
    "\n",
    "# Split the dataset into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "# Verify the split\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb0446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer4.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameters to be tuned\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(clf, params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20975e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer5.\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Define the hyperparameters to be tuned\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(clf, params, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate false positive rate, true positive rate, and area under the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3708d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer6.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Outcome', axis=1)\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Fit the decision tree classifier on the training data\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Visualize the decision tree\n",
    "dot_data = export_graphviz(clf, out_file=None, feature_names=X.columns, class_names=['No Diabetes', 'Diabetes'],\n",
    "                           filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"decision_tree\")\n",
    "\n",
    "# Show the decision tree\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1093d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer7.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load new data for testing\n",
    "new_data = pd.read_csv('diabetes.csv')  # Replace 'new_data.csv' with the actual filename of your new data\n",
    "\n",
    "# Separate features and target variable\n",
    "X_new = new_data.drop('Outcome', axis=1)\n",
    "y_new = new_data['Outcome']\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Predict on new data\n",
    "y_pred_new = best_model.predict(X_new)\n",
    "\n",
    "# Calculate evaluation metrics on new data\n",
    "accuracy_new = accuracy_score(y_new, y_pred_new)\n",
    "precision_new = precision_score(y_new, y_pred_new)\n",
    "recall_new = recall_score(y_new, y_pred_new)\n",
    "f1_new = f1_score(y_new, y_pred_new)\n",
    "\n",
    "# Print evaluation metrics on new data\n",
    "print(\"Accuracy on new data:\", accuracy_new)\n",
    "print(\"Precision on new data:\", precision_new)\n",
    "print(\"Recall on new data:\", recall_new)\n",
    "print(\"F1 Score on new data:\", f1_new)\n",
    "\n",
    "# Create a range of values to vary the input feature\n",
    "feature_to_vary = 'Glucose'  # Replace 'Glucose' with the actual feature you want to perform sensitivity analysis on\n",
    "varying_values = np.linspace(X_new[feature_to_vary].min(), X_new[feature_to_vary].max(), num=10)\n",
    "\n",
    "# Evaluate the model's predictions with varying feature values\n",
    "for value in varying_values:\n",
    "    X_sensitivity = X_new.copy()\n",
    "    X_sensitivity[feature_to_vary] = value\n",
    "    y_pred_sensitivity = best_model.predict(X_sensitivity)\n",
    "    # Perform desired analysis or print the results\n",
    "    # For example:\n",
    "    print(\"Predicted outcome for {} {}: {}\".format(feature_to_vary, value, y_pred_sensitivity))\n",
    "    \n",
    "scenario_1 = X_new.copy()\n",
    "scenario_1['BMI'] += 5  # Increase BMI by 5 units\n",
    "scenario_2 = X_new.copy()\n",
    "scenario_2['Age'] -= 10  # Decrease Age by 10 years\n",
    "\n",
    "# Evaluate the model's predictions on hypothetical scenarios\n",
    "y_pred_scenario_1 = best_model.predict(scenario_1)\n",
    "y_pred_scenario_2 = best_model.predict(scenario_2)\n",
    "# Perform desired analysis or print the results\n",
    "# For example:\n",
    "print(\"Predicted outcome for scenario 1:\", y_pred_scenario_1)\n",
    "print(\"Predicted outcome for scenario 2:\", y_pred_scenario_2)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
