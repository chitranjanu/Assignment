{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8894b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer1. \n",
    "\n",
    "'''  Both t-tests and z-tests are statistical tests used to make inferences about population parameters based on sample data. However, the key difference between the two tests lies in the conditions required to use them.\n",
    "\n",
    "A z-test is used when the population standard deviation is known, and the sample size is large (typically greater than 30). A t-test, on the other hand, is used when the population standard deviation is unknown, and the sample size is small (typically less than 30).\n",
    "\n",
    "Here are some example scenarios where each test would be used:\n",
    "\n",
    "A z-test can be used to determine if the average height of men in a city is significantly different from the national average height of men. The population standard deviation of height is known, and a large sample size (e.g., 500) is taken from the city.\n",
    "\n",
    "A t-test can be used to determine if a new medication is effective in reducing blood pressure. A small sample size (e.g., 20) is taken from a group of individuals with high blood pressure, and their blood pressure is measured before and after taking the medication. The population standard deviation of blood pressure is unknown.\n",
    "\n",
    "In summary, when the sample size is large and the population standard deviation is known, a z-test is appropriate. When the sample size is small or the population standard deviation is unknown, a t-test is more suitable.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da81e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer2. \n",
    "\n",
    "''' A statistical test can be either one-tailed or two-tailed, depending on the directionality of the hypothesis being tested.\n",
    "\n",
    "In a one-tailed test, the hypothesis being tested is directional, meaning it specifies that the effect or relationship being investigated will occur in a particular direction. For example, a one-tailed test might be used to determine if a new drug improves test scores more than a placebo, in which case the hypothesis being tested is that the drug improves test scores.\n",
    "\n",
    "In a two-tailed test, the hypothesis being tested is non-directional, meaning it only specifies that there is a difference or relationship between variables, without indicating the direction. For example, a two-tailed test might be used to determine if there is a difference in test scores between two groups, without specifying which group is expected to have higher scores.\n",
    "\n",
    "The choice of whether to use a one-tailed or two-tailed test depends on the research question and the hypothesis being tested. One-tailed tests are more powerful than two-tailed tests, as they focus the statistical test on a specific direction of effect or relationship. However, one-tailed tests should only be used when there is a strong theoretical reason to expect the effect or relationship to occur in a specific direction.\n",
    "\n",
    "Here's an example of how a one-tailed and a two-tailed test might be used:\n",
    "\n",
    "Suppose a researcher is investigating whether a new study method improves test scores compared to the traditional method. The researcher might have two hypotheses:\n",
    "\n",
    "One-tailed hypothesis: The new study method improves test scores compared to the traditional method.\n",
    "Two-tailed hypothesis: There is a difference in test scores between the new study method and the traditional method.\n",
    "If the researcher believes that the new study method is definitely better than the traditional method, they might use a one-tailed test to specifically test this hypothesis. If the researcher is unsure which method will perform better, they might use a two-tailed test to determine if there is any difference between the two methods.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c8fc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer3. \n",
    "\n",
    "'''  Type 1 and Type 2 errors are two types of errors that can occur in hypothesis testing.\n",
    "\n",
    "Type 1 error occurs when the null hypothesis is rejected, even though it is true. In other words, the test concludes that there is a significant effect or difference when there actually isn't one. The probability of making a Type 1 error is denoted by the symbol alpha (α), and is typically set at a pre-determined level, such as 0.05 or 0.01.\n",
    "\n",
    "An example of a Type 1 error would be if a drug company claims that their new drug reduces the risk of heart attack, but in reality, it does not. If a clinical trial rejects the null hypothesis (that the drug does not reduce heart attack risk) and concludes that the drug is effective, when in fact it is not, a Type 1 error has occurred.\n",
    "\n",
    "Type 2 error, on the other hand, occurs when the null hypothesis is not rejected, even though it is false. In other words, the test fails to detect a significant effect or difference when there actually is one. The probability of making a Type 2 error is denoted by the symbol beta (β), and is affected by factors such as sample size, effect size, and level of significance.\n",
    "\n",
    "An example of a Type 2 error would be if a drug company claims that their new drug reduces the risk of heart attack, and in reality, it does. If a clinical trial fails to reject the null hypothesis (that the drug does not reduce heart attack risk) and concludes that the drug is not effective, when in fact it is, a Type 2 error has occurred.\n",
    "\n",
    "In summary, Type 1 error occurs when a significant effect or difference is detected when there isn't one, while Type 2 error occurs when a significant effect or difference is not detected when there actually is one. The risk of Type 1 and Type 2 errors must be carefully balanced in hypothesis testing to avoid making false conclusions or missing important effects or differences.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c9802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer4. \n",
    "\n",
    "''' Bayes' theorem is a statistical concept that provides a way to update the probability of an event based on new information. It involves calculating the probability of an event occurring based on prior knowledge (prior probability) and new data (likelihood).\n",
    "\n",
    "Bayes' theorem can be expressed mathematically as:\n",
    "\n",
    "P(A|B) = [P(B|A) * P(A)] / P(B)\n",
    "\n",
    "where P(A|B) is the posterior probability of event A given B, P(B|A) is the likelihood of event B given A, P(A) is the prior probability of event A, and P(B) is the prior probability of event B.\n",
    "\n",
    "Here's an example to illustrate how Bayes' theorem works:\n",
    "\n",
    "Suppose a doctor wants to determine the probability that a patient has a certain disease based on the results of a medical test. The prevalence of the disease in the general population is 1%, so the prior probability of a patient having the disease is 0.01 (or 1%).\n",
    "\n",
    "The medical test has a sensitivity of 95% and a specificity of 90%. This means that the test correctly identifies 95% of people who have the disease (true positive rate) and correctly identifies 90% of people who do not have the disease (true negative rate).\n",
    "\n",
    "Now, suppose the doctor administers the test to a patient, and the test comes back positive. The likelihood of a positive test result given that the patient has the disease (B|A) is 0.95, and the likelihood of a positive test result given that the patient does not have the disease (B|~A) is 0.1 (the false positive rate is 1 - specificity, which is 0.1 in this case).\n",
    "\n",
    "Using Bayes' theorem, we can calculate the probability that the patient has the disease given the positive test result (A|B):\n",
    "\n",
    "P(A|B) = [P(B|A) * P(A)] / [P(B|A) * P(A) + P(B|~A) * P(~A)]\n",
    "= [0.95 * 0.01] / [0.95 * 0.01 + 0.1 * (1 - 0.01)]\n",
    "= 0.086\n",
    "\n",
    "So the probability that the patient has the disease given the positive test result is 0.086, or about 8.6%.\n",
    "\n",
    "In this example, Bayes' theorem allows the doctor to update their estimate of the probability that the patient has the disease based on the results of the medical test. The prior probability of the disease is combined with the likelihood of the test result given the disease and the likelihood of the test result given no disease, to arrive at a more accurate estimate of the probability that the patient has the disease. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef19565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer5. \n",
    "\n",
    "''' A confidence interval is a statistical measure that provides an estimate of the range of values within which a true population parameter is likely to fall. It is calculated from a sample of data, and it takes into account the variability of the data and the sample size. A confidence interval is usually expressed as a range of values, along with a level of confidence that the true population parameter falls within that range.\n",
    "\n",
    "For example, suppose a researcher wants to estimate the average height of adult males in a certain population. They collect a random sample of 100 adult males and calculate the mean height of the sample, along with a standard deviation. Using this sample data, they can construct a 95% confidence interval for the true population mean height.\n",
    "\n",
    "The confidence interval is calculated by adding and subtracting a margin of error from the sample mean. The margin of error is based on the standard error of the mean, which is calculated as the standard deviation of the sample divided by the square root of the sample size. The formula for a 95% confidence interval is:\n",
    "\n",
    "Confidence interval = sample mean ± (1.96 * standard error of the mean)\n",
    "\n",
    "In this example, suppose the sample mean height is 180 cm and the standard deviation is 5 cm. The standard error of the mean is calculated as 5 / sqrt(100) = 0.5. Using the formula above, the 95% confidence interval for the true population mean height is:\n",
    "\n",
    "Confidence interval = 180 ± (1.96 * 0.5) = [179.02, 180.98]\n",
    "\n",
    "This means that we can be 95% confident that the true population mean height falls within the range of 179.02 cm to 180.98 cm, based on the sample data.\n",
    "\n",
    "The level of confidence (95% in this example) represents the probability that the true population parameter falls within the calculated confidence interval. In other words, if we were to repeat the sampling process many times and construct confidence intervals using each sample, we would expect about 95% of those intervals to contain the true population parameter.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5015901c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer6. \n",
    "\n",
    "''' Sure, here's an example problem that illustrates the use of Bayes' theorem:\n",
    "\n",
    "Suppose a doctor wants to determine the probability that a patient has a certain rare disease, given the results of a diagnostic test. The disease affects only 1 in 1000 people in the general population, so the prior probability of a randomly selected person having the disease is 0.001.\n",
    "\n",
    "The diagnostic test has a sensitivity of 95% and a specificity of 99%. This means that the test correctly identifies 95% of people who have the disease (true positive rate) and correctly identifies 99% of people who do not have the disease (true negative rate).\n",
    "\n",
    "Now suppose the doctor administers the test to a patient, and the test comes back positive. The question is: what is the probability that the patient has the disease, given the positive test result?\n",
    "\n",
    "Using Bayes' theorem, we can calculate the posterior probability of the patient having the disease given a positive test result as:\n",
    "\n",
    "P(D|T+) = [P(T+|D) * P(D)] / [P(T+|D) * P(D) + P(T+|~D) * P(~D)]\n",
    "\n",
    "where P(D|T+) is the probability of the patient having the disease given a positive test result, P(T+|D) is the probability of a positive test result given that the patient has the disease (i.e., the test sensitivity), P(D) is the prior probability of the patient having the disease, P(T+|~D) is the probability of a positive test result given that the patient does not have the disease (i.e., the false positive rate, which is 1 - specificity), and P(~D) is the prior probability of the patient not having the disease (i.e., 1 - P(D)).\n",
    "\n",
    "Plugging in the given values, we get:\n",
    "\n",
    "P(D|T+) = [(0.95 * 0.001) / [(0.95 * 0.001) + (0.01 * 0.999)]]\n",
    "= 0.086\n",
    "\n",
    "Therefore, the probability that the patient has the disease given a positive test result is about 8.6%.\n",
    "\n",
    "In this example, Bayes' theorem allows the doctor to update their estimate of the probability that the patient has the disease based on the results of the diagnostic test. The prior probability of the disease is combined with the likelihood of the test result given the disease and the likelihood of the test result given no disease, to arrive at a more accurate estimate of the probability that the patient has the disease.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2841b315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer7. \n",
    "\n",
    "''' To calculate the 95% confidence interval for a sample data with a mean of 50 and a standard deviation of 5, we can use the formula:\n",
    "\n",
    "95% confidence interval = sample mean ± (1.96 * standard error)\n",
    "\n",
    "where the standard error is calculated as the standard deviation of the sample divided by the square root of the sample size. However, we need to know the sample size to calculate the standard error. In the absence of that information, let's assume a sample size of 100 for the purpose of this example.\n",
    "\n",
    "The standard error can be calculated as:\n",
    "\n",
    "standard error = standard deviation / sqrt(sample size)\n",
    "= 5 / sqrt(100)\n",
    "= 0.5\n",
    "\n",
    "Using the formula for the 95% confidence interval, we can find the range of values within which we can be 95% confident that the true population mean lies:\n",
    "\n",
    "95% confidence interval = sample mean ± (1.96 * standard error)\n",
    "= 50 ± (1.96 * 0.5)\n",
    "= [49.01, 50.99]\n",
    "\n",
    "Interpretation: We can be 95% confident that the true population mean falls within the range of 49.01 to 50.99, based on the sample data. This means that if we were to take many samples from the same population and construct a 95% confidence interval for each sample, we would expect about 95% of those intervals to contain the true population mean.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b606de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer8. \n",
    "\n",
    "''' The margin of error in a confidence interval is the range of values that is added or subtracted to the point estimate (such as the sample mean) to create an interval estimate of a population parameter (such as the population mean), such that we can be confident that the true population parameter falls within that interval with a certain degree of certainty (such as 95%).\n",
    "\n",
    "A larger sample size generally leads to a smaller margin of error in a confidence interval, all other things being equal. This is because a larger sample size leads to a more precise estimate of the population parameter, which in turn leads to a narrower confidence interval. Specifically, the margin of error is inversely proportional to the square root of the sample size, which means that a four-fold increase in sample size would result in a two-fold decrease in margin of error.\n",
    "\n",
    "Here's an example to illustrate the effect of sample size on margin of error:\n",
    "\n",
    "Suppose a company wants to estimate the average age of its customers, and takes two random samples of different sizes: one with a sample size of 50 and another with a sample size of 500. Let's assume that both samples have the same mean and standard deviation of 35 and 10, respectively.\n",
    "\n",
    "Using a 95% confidence level, we can calculate the margin of error for each sample size as follows:\n",
    "\n",
    "For the sample size of 50:\n",
    "Margin of error = (1.96 * standard error)\n",
    "= (1.96 * (10 / sqrt(50)))\n",
    "= 2.80\n",
    "\n",
    "For the sample size of 500:\n",
    "Margin of error = (1.96 * standard error)\n",
    "= (1.96 * (10 / sqrt(500)))\n",
    "= 0.88\n",
    "\n",
    "We can see that the larger sample size of 500 leads to a much smaller margin of error compared to the smaller sample size of 50. This means that we can be more confident that the true population mean falls within a narrower range of values for the larger sample size, and that the estimate is more precise.\n",
    "\n",
    "In summary, a larger sample size reduces the margin of error, resulting in a more precise estimate of the population parameter'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccc835b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer9. \n",
    "\n",
    "''' To calculate the z-score for a data point with a value of 75, a population mean of 70, and a population standard deviation of 5, we can use the formula:\n",
    "\n",
    "z = (x - μ) / σ\n",
    "\n",
    "where x is the data point, μ is the population mean, and σ is the population standard deviation. Plugging in the values, we get:\n",
    "\n",
    "z = (75 - 70) / 5\n",
    "= 1\n",
    "\n",
    "Interpretation: The z-score of 1 indicates that the data point of 75 is 1 standard deviation above the population mean of 70. In other words, the value of 75 is higher than the average value of the population by one standard deviation. The z-score helps us to standardize the data and compare it with the population mean in terms of standard deviations, which is useful in statistical analysis and hypothesis testing.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e8fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer10. \n",
    "\n",
    "''' To conduct a hypothesis test to determine if the weight loss drug is significantly effective at a 95% confidence interval using a t-test, we need to set up the null and alternative hypotheses and then calculate the t-statistic and the corresponding p-value.\n",
    "\n",
    "Null Hypothesis: The weight loss drug is not significantly effective. (μ = 0)\n",
    "Alternative Hypothesis: The weight loss drug is significantly effective. (μ < 0)\n",
    "\n",
    "Here, we assume a one-tailed test because we want to test if the drug is significantly effective, meaning that it leads to weight loss (μ < 0).\n",
    "\n",
    "We can use the formula for the t-statistic:\n",
    "\n",
    "t = (x̄ - μ) / (s / sqrt(n))\n",
    "\n",
    "where x̄ is the sample mean, μ is the population mean (assumed to be zero), s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "t = (6 - 0) / (2.5 / sqrt(50))\n",
    "= 15.81\n",
    "\n",
    "The degrees of freedom for the t-test is (n-1) = (50-1) = 49, which we can use to find the corresponding p-value using a t-distribution table or calculator.\n",
    "\n",
    "At a 95% confidence level with 49 degrees of freedom, the critical t-value is -1.676.\n",
    "\n",
    "Since our calculated t-value of 15.81 is much greater than the critical t-value of -1.676, we reject the null hypothesis and conclude that the weight loss drug is significantly effective at a 95% confidence interval.\n",
    "\n",
    "The p-value corresponding to our calculated t-value can also be obtained from a t-distribution table or calculator. For a one-tailed test with 49 degrees of freedom and a t-value of 15.81, the p-value is very small (much less than 0.001), which provides strong evidence against the null hypothesis and supports our conclusion that the weight loss drug is significantly effective.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72de84cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer11. \n",
    "\n",
    "''' To calculate the 95% confidence interval for the true proportion of people who are satisfied with their job, we can use the formula:\n",
    "\n",
    "CI = p ± z*(sqrt(p*(1-p)/n))\n",
    "\n",
    "where CI is the confidence interval, p is the sample proportion (65% or 0.65 in this case), z is the critical value of the standard normal distribution for a 95% confidence interval (which is approximately 1.96), and n is the sample size (500 in this case).\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "CI = 0.65 ± 1.96*(sqrt(0.65*(1-0.65)/500))\n",
    "= 0.65 ± 0.042\n",
    "\n",
    "Therefore, the 95% confidence interval for the true proportion of people who are satisfied with their job is (0.608, 0.692). This means that we are 95% confident that the true proportion of people who are satisfied with their job falls between 0.608 and 0.692.\n",
    "\n",
    "Interpretation: We can say with 95% confidence that the proportion of people who are satisfied with their job in the entire population lies between 0.608 and 0.692. Since the confidence interval does not include 0.5 (which would indicate no preference or neutrality), we can conclude that the majority of people in the population are satisfied with their job.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e892a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer12. \n",
    "\n",
    "''' To test if the two teaching methods have a significant difference on student performance, we can use a two-sample t-test with a significance level of 0.01.\n",
    "\n",
    "The null hypothesis is that there is no significant difference between the means of the two samples: H0: μA - μB = 0.\n",
    "\n",
    "The alternative hypothesis is that there is a significant difference between the means of the two samples: Ha: μA - μB ≠ 0.\n",
    "\n",
    "We can use the following formula to calculate the t-test statistic:\n",
    "\n",
    "t = (x̄A - x̄B) / sqrt(Sp^2 * (1/nA + 1/nB))\n",
    "\n",
    "where x̄A and x̄B are the sample means, nA and nB are the sample sizes, and Sp^2 is the pooled variance, calculated as:\n",
    "\n",
    "Sp^2 = [(nA - 1) * S^2A + (nB - 1) * S^2B] / (nA + nB - 2)\n",
    "\n",
    "where S^2A and S^2B are the sample variances.\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "t = (85 - 82) / sqrt(((50-1)*6^2+(50-1)*5^2)/(50+50-2) * (1/50 + 1/50))\n",
    "= 3 / 1.382\n",
    "= 2.17\n",
    "\n",
    "The degrees of freedom for the t-test is (50+50-2) = 98.\n",
    "\n",
    "Using a t-distribution table or a calculator, we find that the critical t-value for a two-tailed test with a significance level of 0.01 and 98 degrees of freedom is ±2.626.\n",
    "\n",
    "Since the calculated t-value (2.17) is within the range of the critical t-values (-2.626 to +2.626), we cannot reject the null hypothesis. Therefore, we can conclude that there is not enough evidence to suggest that there is a significant difference between the mean performances of the two teaching methods.\n",
    "\n",
    "In conclusion, based on the results of the t-test, we cannot conclude that there is a significant difference in the effectiveness of the two teaching methods on student performance at a significance level of 0.01.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0822d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer13. \n",
    "\n",
    "''' To calculate the 90% confidence interval for the true population mean, we can use the following formula:\n",
    "\n",
    "CI = x̄ ± zα/2 * (σ/√n)\n",
    "\n",
    "where x̄ is the sample mean, σ is the population standard deviation, n is the sample size, and zα/2 is the critical value from the standard normal distribution at a confidence level of 90%, which is 1.645.\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "CI = 65 ± 1.645 * (8/√50)\n",
    "= 65 ± 2.33\n",
    "\n",
    "Therefore, the 90% confidence interval for the true population mean is (62.67, 67.33).\n",
    "\n",
    "We can interpret this result as follows: we are 90% confident that the true population mean falls within the range of 62.67 to 67.33.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79f98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer14. \n",
    "\n",
    "''' To conduct a hypothesis test to determine if caffeine had a significant effect on reaction time, we can use a two-tailed t-test with the following null and alternative hypotheses:\n",
    "\n",
    "H0: µ = 0.20 (Caffeine has no significant effect on reaction time)\n",
    "Ha: µ ≠ 0.20 (Caffeine has a significant effect on reaction time)\n",
    "\n",
    "where µ is the population mean reaction time.\n",
    "\n",
    "We will use a significance level of 0.10 for this test (90% confidence interval).\n",
    "\n",
    "The test statistic can be calculated using the formula:\n",
    "\n",
    "t = (x̄ - µ) / (s / √n)\n",
    "\n",
    "where x̄ is the sample mean, µ is the hypothesized population mean, s is the sample standard deviation, and n is the sample size.\n",
    "\n",
    "Plugging in the values, we get:\n",
    "\n",
    "t = (0.25 - 0.20) / (0.05 / √30)\n",
    "= 2.45\n",
    "\n",
    "The degrees of freedom for this test are n-1 = 29.\n",
    "\n",
    "Using a t-table or calculator with 29 degrees of freedom, we find that the critical values for a two-tailed test at a 0.10 significance level are ±1.699.\n",
    "\n",
    "Since our test statistic (2.45) is greater than the critical value (1.699), we reject the null hypothesis and conclude that there is a significant effect of caffeine on reaction time at a 90% confidence interval.\n",
    "\n",
    "In other words, we have evidence to suggest that caffeine does have a significant effect on reaction time.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
